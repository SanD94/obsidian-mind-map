#programming #programlama 

# Concurrency

*Concurrency* is when the execution of two or more pieces of code act as if they run at the same time. *Parallelism* is when they *do* run at the same time. To have concurrency, you need to run code in an environment that can switch execution between different parts of your code when it's running. This is often implemented using things such as fibers, threads, and processes. To have parallelism, you need hardware that can do two things at once. This might be multiple cores in a CPU, multiple CPUs in a computer, or multiple computers connected together.

Why is writing concurrent and parallel code so difficult? One reason is that you learned to program using sequential systems, and your languages have features that are relatively safe when used sequentially but become a liability once two things can happen at the same time. 

## Breaking Temporal Coupling

You need to allow for concurrency and to think about decoupling any time or order dependencies. In doing so, you can gain flexibility and reduce any time-based dependencies in many areas of development: workflow analysis, architecture, design, and deployment. The result will be systems that are easier to reason about, that potentially respond faster and more reliably.

### Looking for Concurrency

On many projects, you need to model and analyze the application workflows as part of the design. We'd like to find out what *can* happen at the same time, and what *must* happen in a stirct order. One way to do this is to capture the workflow using a notation such as the *activity diagram*.

	Analyze Workflow to Improve Concurrency

### Opportunities for Concurrency

Activity diagrams show the potential areas for concurrency, but have nothing to say about whether these areas are worth exploiting. When you are designing for currency, you should be hoping to find activities that take time, but not time in your code. Waiting for an input from external services would normally stall your program until it is completed. These are all opportunities to do something more productive than the CPU equivalent of twiddling one's thumbs.

### Opportunities for Parallelism

Remember the distinction: concurrency is a software mechanism, and parallelism is a hardware concern. The ideal things to split are pieces of work that are relatively independent -- where each can proceed without waiting for anything from the others. A common pattern is to take a large piece of work, split it into independent chunks, process each in parallel, then combine the results.

## Shared State is Incorrect State

When there are some works which are handled concurrently, there may be cases when one thing is accessed by several jobs. If one of the jobs try to update that state without informing other jobs, you are in the middle of a crisis. So, in order to solve this problem, you can use semaphores or other forms of mutual exclusion. A semaphore is simply a *thing* that only one person can own at a time. You can create a semaphore and then use it to control access to some other resource. However, there are some problem with this approach. Probably the most significant is that it only works because everyone who accesses the data agrees on the convention of using the semaphore. If someone forgets then you're back in chaos. You can solve the problem by making the resource transactional.

	Random Failures are Often Concurrency Issues

Concurrency in a shared resource environment is difficult, and managing it yourself is fraught with challenges.

## Actors and Processes

*Without writers, stories would not be written, without actors, stories could not be brought to life. -- Angie-Marie Delsante*

An *actor* is an independent virtual processor with its own local state. Each actor has a mailbox. When a message appears in the mailbox and the actor is idle, it kicks into life and processes the message. When it finishes processing, it processes another message in the mailbox, or, if the mailbox is empy, it goes back to sleep.

A *process* typically a more general-purpose virtual processor, often implemented by the OS to facilitate concurrency. Processes can be constrained (by convention) to behave like actors, and that's the type of process we mean here.

	Use Actors for Concurrency Without Shared State

```js
const customerActor = {
	'hungry for pie': (msg, ctx, state) => {
		return dispatch(
			state.waiter,
			{ type: "order", customer: ctx.self, wants: 'pie' }
		)
	},
	'put on table': (msg, ctx, state) => {
		console.log(`${ctx.self.name} sees "${msg.food}" appear on the table`);
	},
	'no pie left': (msg, ctx, state) => {
		console.log(`${ctx.self.name} sulks...`)
	}

}

const waiterActor = {
	'order': (msg, ctx, state) => {
		if (msg.wants == "pie")
			dispatch(
				state.pieCase,
				{ type: "get slice", customer: msg.customer, waiter: ctx.self }
			)
		else
			console.dir(`Don't know how to order ${msg.wants}`)
	},
	'add to order': (msg, ctx) => {
		console.log(`Waiter add ${msg.food} to ${msg.customer.name}'s order`)
	},
	'error': (msg, ctx) => {
		dispatch(
			msg.customer,
			{ type: 'no pie left', msg: msg.msg }
		);
		console.log(`\nThe waiter apologizes to ${msg.customer.name} : ${msg.msg}`)
	}
}

const pieCaseActor = {
	'get slice': (msg, context, state) => {
		if (state.slices.length == 0) {
			dispatch(
				msg.waiter,
				{ type: 'error', msg : "no pie left", customer: msg.customer }
			);
			return state;
		} else {
			var slice = state.slices.shift() + " pie slice";
			dispatch(
				msg.customer,
				{ type: 'put on table', food: slice}
			);
			dispatch(
				msg.waiter,
				{ type: 'add to order', food: slice, customer: msg.customer }
			);
			return state;
		}
	}
}


const actorSystem = start();

let pieCase = start_actor(
	actorSystem,
	'pie-case',
	pieCaseActor,
	{ slices: ["apple", "peach", "cherry"]}
);

let waiter = start_actor(
	actorSystem,
	'waiter',
	waiterActor,
	{ pieCase: pieCase }
);

let c1 = start_actor(actorSystem, 'customer1',
					 customerActor, { waiter : waiter });
let c2 = start_actor(actorSystem, 'customer2',
					 customerActor, { waiter : waiter });

```


Int the actor model, there's no need to write any code to handle concurrency, as there is no shared state. There's also no need to code in explicit end-to-end "do this, do that" logic, as the actors work it out for themselves based on the messages they receive.

## Blackboards

*The writing is on the wall... -- Daniel 5*

Key features of the blackboard approach are:

* None of the agents needs to know of the existence of any other agent -- they watch the board for new information, and add their findings.
* The agents may be trained in different disciplines, may have different levels of education and expertise, and may not even work in the same area. They share a desire to solve the problem, but that's all.
* Different agents may come and go during the course of the process, and may work different times.
* There are no restrictions on what may be placed on the blackboard. It may be any kind of data.

This is a from of *laissez faire* concurrency.

	Use Blackboards to Coordinate Workflow

These kinds of system can be more troublesome to deploy and manage, as there are more moving parts. To some extent this is offset by the fact that the system is more granular, and can be updated by replacing individual actors, and not the whole system.